# Turbine Power Prediction
A machine learning model with a data pipeline to capture, clean, extract, analyze, and store wind turbine data.
# Description
## Project Function
Currently companies are using formulas and linear analysis in attempts to model wind turbines, however have come up short due to the complexity of real world wind conditions. This project has attempted to take the data collected by the power curve working group, a member of the Consortium for the Advancement of Remote Sensing, and create a more realistic model of wind turbines.
## Power Curve Working Group Dataset
The dataset used for this analysis was the Power Curve Working Groups first dataset that comes from a moderately complex cold climate Swedish site surrounded by relatively low forestry. With values collected on approximately 10 minute intervals of mean wind speed and windvane at various heights as well as information on the turbine's density. The dataset contains over 10,000 examples spanning over a years worth of time and a total of 28 features.  
Location: https://pcwg.org/ (Select the dataset 1 to replicate results of this project)
## Pipeline Architecture
![image](https://github.com/user-attachments/assets/0342e015-5abf-41e4-87fe-1911c3e73be6)
I utilized a batch ingestion pipeline, collecting the raw data with python and stored it within a data lake with AWS S3. I then used pandas a python library to transform the data, removing missing and outlier data points. Storing this clean data in a data warehouse in AWS S3. Next, I used scikit-learn a python library to extract features and run a machine learning model on the data. I collected the results from the machine learning forecasting as well as the cleaned data from the warehouse and created data visualizations within Tableau.
## Data Quality & Provence
The dataset the owners of the dataset is the power curve working group who collected the data from a wind turbine site in Sweden. It has not been documented how exactly the data has been processed outside of a blanket statement of a standard filtering system. The data has been changed over time with eight revisions to the dataset being made by the same individual. He has listed what was done each time to document the changes such as adding new columns and fixing missing values. The initial seven changes were made between 2013 to 2014; however, the fixing of missing values was done in 2024. The changes made are specified as pulling data from other public datasets to expand this specific dataset. I do trust this data as only one individual has manipulated the data since it has been published with detailed explanations as to what was changed and when. The values themselves are also being collected with LiDAR which a more accurate system than other alternatives thus giving more confidence to the accuracy of the values. Going over the data provenance questions, anyone can access a copy of this dataset by going to their website, but to make edits to the data it only is those who work for the group. The security to protect the data and privacy are not allowing people to access or manipulate the data at the source. There are not a lot of privacy protection being used as the data is not pertaining to personal or health information, however the exact location it was collected was not disclosed. As the previous versions and the actual documentation of changes outside of the self-reported revisions are not available I would say the data is not compliant with new regulations. The data source I am using would not be approved for use in a company as there is not enough documentation as to revisions and authenticity of the data, but for a research project on the capabilities of machine learning to predict power generated from wind turbines without having access to our own wind turbines this may be the best option. The only concern that comes from this data set is the missing values for some points in the dataset due to either mistakes in data transfer or equipment error, which does impact approximately half the data. However, the data does span over 2 years thus excluding the observations with missing values there still is a significant amount of data available.
## Data Transformation Models
The first transformation I had on the data was to transform the type of the time from a string to a date time variable. I also had to transform another sensor value from a string to a float as it was stored differently than the rest of the variables. I then transformed the missing data that they stored as the value of -99.99 to null values then removed those and any other missing data points from the dataset. With my clean data I then applied a min max scaler to the features to prevent numerical instability interferring with the model's performance. The data was then split into training and testing sets of an 80/20 split. The machine learning model I selected to utilize was a random forrest regressor from scikit-learn a python library. After training the model I was able to achieve an R-Square of 98% and a Mean Percentage Error of only 5% on the testing dataset.
## Infographic: 
Final infographic describing the results of the engineering task accomplished. Examples can be provided if needed.
## Code: 
A link to GitHub Repository
## Thorough Investigation: 
This critically assesses the viability of your idea: Based on the results of this project (your pilot project, your prototype, etc), from a technical leadership point of view, what are your conclusions or recommendations for continuing this project in terms of scaling it up? How would you assess the innovativeness of your project? Any technical or platform concerns, difficulties, or limitations of the pipeline for the project? Based on your experience and results, what next step would you recommend to take this project to the next level/phase?
